{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import requests\n",
    "from lxml import etree\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "# Code Design taken from: https://github.com/chaitanyanettem\n",
    "# Several Modifications for efficiency and use\n",
    "\n",
    "class cik:\n",
    "\tdef __init__(self, cik):\n",
    "\t\tself.cik = str(cik)\n",
    "\t\tself.url = \"http://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={cik_arg}&type=13F-HR&dateb=&owner=exclude&count=40&output=atom\".format(cik_arg=self.cik)\n",
    "\t\n",
    "\t\t# Uncomment to validate CIK:\n",
    "\t\t'''\n",
    "\t\tif not self.validate():\n",
    "\t\t\tsys.exit(\"Invalid CIK/Ticker.\")\n",
    "\t\t'''\n",
    "\t\t# The etree.parse() method fetches atom feed from the URL constructed above.\n",
    "\t\t# This atom feed contains a list of all 13F-HR filings for the given CIK.\n",
    "\t\tself.parsed = etree.parse(self.url)\n",
    "\t\tself.txt_link = \"\"\n",
    "\t\tself.primary_doc = \"\"\n",
    "\t\tself.info_table = \"\"\n",
    "\t\n",
    "\t\n",
    "\tdef validate(self):\n",
    "\t\t# Validate given ticker by making a call to EDGAR website with constructed URL.\n",
    "\t\tcik_validation = requests.get(self.url)\n",
    "\t\tif not '<?xml' in cik_validation.content[:10]:\n",
    "\t\t\treturn False\n",
    "\t\telse:\n",
    "\t\t\treturn True\n",
    "\n",
    "\tdef find_first_txt_link(self):\n",
    "\t\t# Finds index link of the first filing and from that link, constructs the link\n",
    "\t\t# to the full txt submission and stores it in self.txt_link\n",
    "\n",
    "\t\tentry_tag = \"{http://www.w3.org/2005/Atom}entry\"\n",
    "\t\tlink_tag = \"{http://www.w3.org/2005/Atom}link\"\n",
    "\t\tfind_string = \"{ent}/{link}\".format(ent=entry_tag, link=link_tag)\n",
    "\t\t\n",
    "\t\tlink = self.parsed.find(find_string).get(\"href\")\n",
    "\t\t# Replaces \"-index.htm\" with \".txt\"\n",
    "        \n",
    "\t\tlink_edit_index = link.find(\"-index.htm\")\n",
    "\t\tself.txt_link = ''.join([link[:link_edit_index], \".txt\"])\n",
    "\n",
    "\tdef split_txt_file(self):\n",
    "\t\t# Splits the retrieved txt file into two parts:\n",
    "\t\t#\n",
    "\t\t# 1. The primary_doc which contains information about the institution (name,\n",
    "\t\t#    address etc.)\n",
    "\t\t# 2. The info_table which contains details regarding number of shares, value etc.\n",
    "\n",
    "\t\ttxt_file = requests.get(self.txt_link).content\n",
    "\t\titer_open_xml = re.finditer(r\"<XML>\", txt_file)\n",
    "\t\titer_close_xml = re.finditer(r\"</XML>\",txt_file)\n",
    "\t\t\n",
    "\t\topening_indices = [index.start()+len(\"<XML>\\n\") for index in iter_open_xml]\n",
    "\t\tclosing_indices = [index.start() for index in iter_close_xml]\n",
    "\n",
    "\t\tself.primary_doc = txt_file[opening_indices[0]:closing_indices[0]]\n",
    "\t\tself.info_table = txt_file[opening_indices[1]:closing_indices[1]]\n",
    "\n",
    "\t\t# Uncomment the following if you want to see xml written to files:\n",
    "\t\t# \t\t\n",
    "\t\t# f_prim_doc = open(\"primary_doc.xml\",\"w\")\n",
    "\t\t# f_prim_doc.write(self.primary_doc)\n",
    "\t\t# f_prim_doc.close()\n",
    "\t\t# f_info_table = open(\"info_table.xml\",\"w\")\n",
    "\t\t# f_info_table.write(self.info_table)\n",
    "\t\t# f_info_table.close()\n",
    "\n",
    "\tdef prep_csv_string(self, commaList):\n",
    "\t\t\n",
    "\t\tcommaSeparated = []\n",
    "\t\tfor x in commaList:\n",
    "\t\t\tif x is not None:\n",
    "\t\t\t\tcommaSeparated.append(x.text)\n",
    "\t\t\telse:\n",
    "\t\t\t\tcommaSeparated.append('Empty')\n",
    "\t\tcommaSeparated = \",\".join(commaSeparated)\n",
    "\t\treturn commaSeparated\n",
    "\n",
    "\t\t\n",
    "\tdef get_primary_doc_csv(self):\n",
    "\t\t# Although the spec lists a lot of information for primary_doc, a lot\n",
    "\t\t# of it is things like addresses and agent names. So I'm ignoring everything except\n",
    "\t\t# periodOfReport, tableEntryTotal and tableValueTotal\n",
    "\n",
    "\t\tprimary_doc_parse = etree.fromstring(self.primary_doc)\n",
    "\n",
    "\t\tnamespace = \"{http://www.sec.gov/edgar/thirteenffiler}\"\n",
    "\t\theaderData_tag = \"\".join([namespace, \"headerData/\"])\n",
    "\t\tfilerInfo_tag = \"\".join([namespace, \"filerInfo/\"])\n",
    "\t\tformData_tag = \"\".join([namespace, \"formData/\"])\n",
    "\t\tsummaryPage_tag = \"\".join([namespace, \"summaryPage/\"])\n",
    "\n",
    "\t\tperiodOfReport_tag = \"\".join([headerData_tag, filerInfo_tag, namespace, \"periodOfReport\"])\n",
    "\t\ttableEntryTotal_tag = \"\".join([formData_tag, summaryPage_tag, namespace, \"tableEntryTotal\"])\n",
    "\t\ttableValueTotal_tag = \"\".join([formData_tag, summaryPage_tag, namespace, \"tableValueTotal\"])\n",
    "\t\t\n",
    "\t\tcommaList = []\n",
    "\t\tcommaList.append(primary_doc_parse.find(periodOfReport_tag))\n",
    "\t\tcommaList.append(primary_doc_parse.find(tableEntryTotal_tag))\n",
    "\t\tcommaList.append(primary_doc_parse.find(tableValueTotal_tag))\n",
    "\n",
    "\t\tcommaSeparated = self.prep_csv_string(commaList)\n",
    "\n",
    "\t\tzer = commaSeparated.split(',')[0]\n",
    "\t\tone = commaSeparated.split(',')[1]\n",
    "\t\ttwo = commaSeparated.split(',')[2]\n",
    "\t\t#zer = primary_doc_parse.find(periodOfReport_tag)\n",
    "\t\t#one = primary_doc_parse.find(tableEntryTotal_tag)\n",
    "\t\t#two = primary_doc_parse.find(tableValueTotal_tag)\n",
    "        \n",
    "\t\t#print zer , one ,two\n",
    "        \n",
    "\t\treturn{'CIK' : self.cik,\n",
    "\t\t\t\t'periodOfReport': zer,\n",
    "\t\t\t\t'tableEntryTotal': one,\n",
    "\t\t\t\t'tableValueTotal': two\n",
    "\t\t\t\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_postgrestable(readtablename):\n",
    "    \"\"\"\n",
    "    returns : Pandas.Dataframe\n",
    "    \n",
    "    otherwise: returns False\n",
    "    and prints exception\n",
    "    \n",
    "    \"\"\"\n",
    "    engine = create_engine('postgresql://irtza:hedgefund@localhost:5432/oquantdatabase')\n",
    "    df = False\n",
    "    try:\n",
    "        df = pd.read_sql_query('select * from '+readtablename,con=engine)\n",
    "    except Exception, e:\n",
    "        print str(e)\n",
    "    return df\n",
    "\n",
    "def read_db():\n",
    "    engine = create_engine('postgresql://irtza:hedgefund@localhost:5432/oquantdatabase')\n",
    "    df = 0\n",
    "    try:\n",
    "        df = pd.read_sql_query('select * from \"HedgeFundResults\"',con=engine)\n",
    "    except Exception, e:\n",
    "        print str(e)\n",
    "    return df\n",
    "\n",
    "def savetoPostgres(df , table_name):\n",
    "    '''\n",
    "    Saves a DataFrame to a table in oquantdatabase PostgresSQL\n",
    "    1st arg : DataFrame\n",
    "    2nd arg : tablename in postgres .. will be created and overwritten\n",
    "    \n",
    "    Default: if exists = True\n",
    "    '''\n",
    "    engine = create_engine('postgresql://irtza:hedgefund@localhost:5432/oquantdatabase')\n",
    "    try:\n",
    "        #database table is also called bigdata\n",
    "        pd.DataFrame.to_sql(df,table_name, engine,if_exists='replace')\n",
    "        print \"oquantdatabase table: \"+table_name+\": Over-written\"\n",
    "\n",
    "    except Exception ,e:\n",
    "        print str(e)\n",
    "        return False\n",
    "\n",
    "    else:\n",
    "        print \"All the data has been BULK inserted to Postgresql: \"\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = read_postgrestable(\"hedgefund\")\n",
    "listciks = df['CIK'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "#### UNCOMMENT TO RE-GET data#####\n",
    "#for item in listciks:\n",
    "#    try:\n",
    "#        ticker = cik(item)\n",
    "#        ticker.find_first_txt_link()\n",
    "#        ticker.split_txt_file()\n",
    "#        result.append(ticker.get_primary_doc_csv())\n",
    "#        print \"GET-TING CIK : \" , item\n",
    "#    except:\n",
    "#        result.append(\n",
    "#            {'CIK' : str(item),\n",
    "#             'periodOfReport': pd.np.nan,\n",
    "#             'tableEntryTotal': pd.np.nan,\n",
    "#             'tableValueTotal': pd.np.nan\n",
    "#            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(psycopg2.ProgrammingError) relation \"hedgefundresults\" does not exist\n",
      "LINE 1: select * from HedgeFundResults\n",
      "                      ^\n",
      " [SQL: 'select * from HedgeFundResults']\n"
     ]
    }
   ],
   "source": [
    "if result:\n",
    "    resdf = pd.DataFrame(result)\n",
    "    resdf.dropna(inplace=True)\n",
    "    resdf.drop_duplicates(inplace =True)\n",
    "    resdf = df.merge(resdf,on='CIK').drop_duplicates('CIK')\n",
    "\n",
    "    resdf['tableValueTotal'] = pd.to_numeric(resdf['tableValueTotal'])\n",
    "    resdf['tableEntryTotal'] = pd.to_numeric(resdf['tableEntryTotal'])\n",
    "    savetoPostgres(resdf,\"HedgeFundResults\")\n",
    "\n",
    "#if DB is already there read\n",
    "resdf = read_postgrestable(\"HedgeFundResults\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           4000945\n",
       "1           4049169\n",
       "2            413092\n",
       "3             27563\n",
       "4           1579703\n",
       "5            374459\n",
       "6            716607\n",
       "7           1160723\n",
       "8          11539597\n",
       "9            996579\n",
       "10           236530\n",
       "11         17133230\n",
       "13            33133\n",
       "14         13742466\n",
       "15          5492250\n",
       "16            16330\n",
       "17             6086\n",
       "18         10665458\n",
       "19           228701\n",
       "21         12869112\n",
       "22         20801604\n",
       "23          3781572\n",
       "25            49917\n",
       "26           208419\n",
       "27      12080354459\n",
       "28        160440230\n",
       "29          3361365\n",
       "30           157613\n",
       "31            84372\n",
       "32         67193873\n",
       "           ...     \n",
       "2575       14446288\n",
       "2576              0\n",
       "2577         104860\n",
       "2578              0\n",
       "2579         616805\n",
       "2580         101420\n",
       "2581         234088\n",
       "2582         869602\n",
       "2583        1106430\n",
       "2584        3738496\n",
       "2585         165018\n",
       "2587     4775848000\n",
       "2588          83108\n",
       "2589          99399\n",
       "2590         217682\n",
       "2592         316046\n",
       "2593         707841\n",
       "2594         125154\n",
       "2595        3508470\n",
       "2596          65567\n",
       "2597         675794\n",
       "2598         167712\n",
       "2599         862940\n",
       "2600          85361\n",
       "2601          52396\n",
       "2602      169548161\n",
       "2603          46517\n",
       "2604              0\n",
       "2605              0\n",
       "2606         236515\n",
       "Name: tableValueTotal, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(resdf['tableValueTotal'][0])\n",
    "#resdf['tableValueTotal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
